\begin{frame}
  \begin{center}
    {\huge A* Sampling
    } \\
    Maddison,Tarlow,Minka
  \end{center}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Introduction - Partition Function Woes}
  \begin{itemize}
  \item Gibbs Distribution
    \begin{align*}
      \Pr(\x;\theta) =\frac{\exp(\theta^T\psi(\x))}{Z} \tag{$Z=\sum_{\x} \theta^T\psi(\x)$}
    \end{align*}
  \item ML parameter estimation,
    \begin{align*}
      - \nabla_\theta \log LLH = \E_{\Pr(x;\theta)}\left[\psi(\x)\right] - \frac{1}{T} \sum_i\psi(x_i)
    \end{align*}
  \item   Computing $\E_{\Pr(x;\theta)}[.]$ often intractable.
  % Sampling from posterior is hard
  \item So we resort to approximations. % MCMC, Contrastive Divergence
    %% \item This paper provides a way to obtain exact samples from a intractable distribution.
    %% sampling is inherently tied to Z
    %% but computing Z is #P hard in general
  \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}<1-3>[label=framelabel]{Detour - Gumbel Distribution}
  Gumbel with location parameter $m$, $Gumbel(m)$.
  \begin{itemize}
    %% & CDF(x;\mu) = \exp \left(-\exp\left(-x+\mu\right)\right) \\
  \item CDF for $Gumbel(m)$, $\Pr(G\le g) = \exp(-\exp(-g+m))$ \\
    \pause
  \item Mean is $m+\gamma$, Variance is $\frac{\pi^2}{6}$.
    \pause
  \item\alert<4->{For $G(i) \sim Gumbel(0)$, and any $B \subseteq [n]$
    \begin{align*}
      & \argmax_{i \in B}{G(i)+\phi(i)} \sim \frac{\exp(\phi(i))}{\sum_{i \in B} \exp(\phi(i))} \\
      & \max_{i \in B}{G(i)+\phi(i)} \sim Gumbel\left(\log \sum_{i \in B} \exp(\phi(i))\right) \tag{Max-Stability}
      %% proof in \cite{hazan}
    \end{align*}
  }
  \end{itemize}
  %% \pause\tikz[overlay,remember picture]{\draw[draw=red,thick,fill opacity=0.2] ($(boxlabel)+(-0.5,0.4)$) rectangle ($(boxlabel)+(11,-4.5)$);}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}{Key Properties}
%% \end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Gumbel-Max Trick (Discrete Case)}
  Suppose you have a discrete distribution specified by un-normalized log probabilities $\{\phi(i)\}_{i=1}^{k}$ over k configurations $\{x_1,\cdots,x_k\}$, i.e.,
  \begin{align}
    \Pr(x_i) = \frac{\exp\phi(i)}{\sum_j\exp\phi(j)} \label{eq:gibbs}
  \end{align}
  We can draw samples $x_i \sim \Pr$ from this distribution using the following procedure.
  \begin{align*}
    & \text{Sample} \qquad G(i) \sim Gumbel(0) \text{ for } i=1..k\\
    & \text{then} \qquad \text{ Choose } x_j \text{ such that } j= \argmax_i \{G(i) +\phi(i)\} \tag{the argmax of the perturbed probabilities is distributed as eq.\ref{eq:gibbs} above}
  \end{align*}

\end{frame}
\againframe<4>{framelabel}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Benefits} %{Wait ... So What?}
  %% All this is cute, but what is the benefit?
  \begin{itemize}
  \item Partition Function evaluation $\implies$ Computing (many) perturbed MAPs. % We have reduced a to b. No need to compute the partition function, as long as you can compute the (perturbed) argmax!
  \item \emph{Exact} samples from the target distribution. % Note that the samples are exact. (No approximations!)
    %(examples when things are approximations, MCMC ``once the chain reaches stationary distribution'')
  \end{itemize}
  But ...
  \begin{itemize}
  \item What happens if we move from discrete to continuous space?
  \item \textsc{Question:} Is There A Gumbel Max Trick for Continuous Distributions? %% One that does not resort to making infinite??exponential perturbations?
    \pause
  \item {\color{red} This paper --- Yes!}
  \end{itemize}
\end{frame}

%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}{Gumbel and the Partition Function}
  
%% \end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Perturbing Gumbel Process Variates}
  %% just put image
  For $B \subseteq \Omega$,
  \begin{align*}
  \max \{G_k \mid X_k \in B\} \sim Gumbel(log \mu(B)) \\
  \argmax \{G_k \mid X_k \in B\} \sim \frac{\exp(\phi(x))1_{x \in B}}{\mu(B)} \\
  \end{align*}
  Then $\{ \max \{G_k \mid X_k \in B\} \mid B \subseteq \Omega\}$ is a Gumbel Process.
\end{frame}

%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}{High Dimensional Sampling is Exponential}

%% \end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Main Idea}
  \emph{We can transform a Gumbel process into another by adding the difference of their log densities.} \\
  \begin{align*}
  & \mu(B) = \int_{x\in B} \exp(\phi(x)) \\
  & \nu(B)=\int_{x\in B} \exp(i(x)) \\
  & \text{ Let $o(x) = \phi(x) - i(x)$ be bounded} \\
  & \{\{G_k + o(X_k) \mid X_k \in B\} \mid B \subseteq \R^d\} \text{ is a Gumbel Process with measure $\mu$}
  \end{align*}
   
  %% So if I can easily draw samples from the prior and I have a way to compute the bound on the log-likelihood, then I can use Gumbel.
\end{frame}
\begin{frame}{Progress So Far}
  \begin{itemize}
  \item We wanted to draw samples from target distribution.
  \item We reduced it to computing argmax of a sequence of samples from a exotic distribution. (because argmax follows the target dist)
  \end{itemize}
  Problems
  \begin{itemize} 
  \item Drawing samples from the distribution requires knowing Z of my target distribution.
  \item We do not want to draw infinite samples to compute argmax on.
  \end{itemize}
  Solutions
  \begin{itemize} 
  \item I can draw samples from easier distribution, because I know its log Z. and then add the hard part to the samples before taking argmax.
  \item Do A* search.
  \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Top-Down Construction of Gumbel Process}
  Assume log Z is computable for now.
\end{frame}



\begin{frame}{Main Idea}
  \centering
  \begin{tikzpicture}[scale=0.8]
    %% \draw[step=0.5,gray] (-5,-5) grid (5,5);
    \draw[ultra thick,gray] plot[smooth] coordinates {(-6,0)(-5,0)(-3,3) (0,-1) (3,3) (5,0)};
    \node (ox) at (-4,-1) {o(x)};

    %% \begin{axis}[height=10cm,width=10cm]
    %%   \addplot[ultra thick,gray,smooth] coordinates {
    %%     (-6,0)(-5,0)(-3,3) (0,-1) (3,3) (5,0)}
    %%   node [pos=0.9,below left] {o(x)};
    %% \end{axis}
    
    \only<2>{
      \path[draw,dotted,blue,very thick] (-5,5) -- (5,5);
    }
    %% \addplot+[ycomb,black,thick] {1};
    %% \node[above] (g1) at (0,4) {};

    \onslide<2->{
      \path[draw,red,thick] (0,-1) -- (0,4) circle (1.5pt);
      \node[above] at (0,4.25) {$g_1+o(x_1)$};
    }
    
    \only<2,3>{
      \path[draw,green,dotted,very thick] (-5,4) -- (5,4);
    }
    
    \onslide<3->{
      \path[draw,red,thick] (-3,3) -- (-3,2) circle (1.5pt);
      \node[below] at (-3,1.5) {$g_2+o(x_2)$};
    }

    \only<3,4,5>{
      \path[draw,dotted,blue,very thick] (-5,3.5) -- (0,3.5);
    }
    
    \onslide<4->{
      \path[draw,red,thick] (3,3) -- (3,4.5) circle (1.5pt);
      \node[below] at (3,5.25) {$g_3+o(x_3)$};
    }
    \only<3->{
      \path[draw,dotted,blue,very thick] (0,5) -- (5,5);
    }
    \only<4->{
      \path[draw,green,dotted,very thick] (-5,4.5) -- (5,4.5);
    }
  \end{tikzpicture}  
\end{frame}

\begin{frame}
  But
\end{frame}
