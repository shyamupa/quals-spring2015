\begin{frame}
  \begin{center}
    {\huge A* Sampling
    } \\
    Maddison,Tarlow,Minka
  \end{center}
\end{frame}

\begin{frame}{Premise of the Paper}
  %% what is the paper trying to solve
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Partition Function Woes}
  Gibbs Distribution
  \begin{align*}
    \Pr(\x;\theta) =\frac{\exp(\theta^T\phi(\x))}{Z} \tag{$Z=\sum_{\x} \theta^T\phi(\x)$ is partition function}
  \end{align*}
  ML parameter estimation,
  \begin{align*}
    - \nabla_\theta \log LLH = \E_{\Pr(x;\theta)}\left[\phi(\x)\right] - \frac{1}{T} \sum_i\phi(x_i)
  \end{align*}
  Computing $\E_{\Pr(x;\theta)}$ is not usually tractable. Resort to approximations - MCMC, Contrastive Divergence etc.
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Gumbel Distribution}
  \begin{align*}
    & Gumbel(\mu) = \text{gumbel distribution with location parameter } \mu \\
    & CDF(x;\mu) = \exp \left(-\exp\left(-x+\mu\right)\right) \\
    & Mean = \mu+\gamma \tag{a fixed offset away from location parameter} \\
    & Variance = \frac{\pi^2}{6}
  \end{align*}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Key Properties}
  For $G(i) \sim Gumbel(0)$,
  \begin{align*}
    & \argmax_i{G(i)+\phi(i)} \sim \frac{\exp(\phi(x))}{Z} \\
    & \max_i{G(i)+\phi(i)} \sim Gumbel(\log Z) \tag{Max-Stability from \cite{hazan}}
  \end{align*}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Gumbel-Max Trick (Discrete Case)}
  Suppose you have a discrete distribution specified by un-normalized log probabilities $\{\phi(i)\}_{i=1}^{k}$, i.e.,
  \begin{align}
    \Pr(x_i) = \frac{\exp\phi(i)}{\sum_j\exp\phi(j)} \label{eq:gibbs}
  \end{align}
  We can draw samples $x_i \sim \Pr$ from this distribution using the following procedure.
  \begin{align*}
    & \text{Sample} \qquad G(i) \sim Gumbel(0) \text{ for } i=1..k\\
    & \text{then} \qquad x_i \sim \argmax_i \{G(i) +\phi(i)\} \tag{the argmax of the perturbed probabilities is distributed as eq.\ref{eq:gibbs} above}
  \end{align*}
  No need to compute the partition function, as long as you can compute the (perturbed) argmax!
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Is There A Gumbel Max Trick in Continuous Case?}
  This paper --- Yes!
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Gumbel and the Partition Function}
  
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Gumbel Process}
  %% just put image
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{High Dimensional Sampling is Exponential}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Top-Down Construction of Gumbel Process}
Assume log Z is computable for now.
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Main Idea}
  log Prior + log LLH = log Posterior
  Sampling from posterior is hard.
  Suppose 
\end{frame}
